{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                    24\n",
       "combinations      (250, 5000, 256, 0.001, 0.001)\n",
       "train accuracy                          0.711367\n",
       "val accuracy                               0.563\n",
       "Name: 24, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(df[\"val accuracy\"])\n",
    "df.iloc[a.index(max(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>combinations</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>val accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(200, 4000, 256, 0.001, 0.001)</td>\n",
       "      <td>0.664857</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(200, 4000, 256, 0.001, 0.0001)</td>\n",
       "      <td>0.665939</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(200, 4000, 256, 0.0001, 0.001)</td>\n",
       "      <td>0.412286</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(200, 4000, 256, 0.0001, 0.0001)</td>\n",
       "      <td>0.412306</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(200, 4000, 512, 0.001, 0.001)</td>\n",
       "      <td>0.632755</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(200, 4000, 512, 0.001, 0.0001)</td>\n",
       "      <td>0.633082</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(200, 4000, 512, 0.0001, 0.001)</td>\n",
       "      <td>0.372020</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(200, 4000, 512, 0.0001, 0.0001)</td>\n",
       "      <td>0.371959</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(200, 5000, 256, 0.001, 0.001)</td>\n",
       "      <td>0.692286</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(200, 5000, 256, 0.001, 0.0001)</td>\n",
       "      <td>0.694714</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(200, 5000, 256, 0.0001, 0.001)</td>\n",
       "      <td>0.425061</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(200, 5000, 256, 0.0001, 0.0001)</td>\n",
       "      <td>0.425163</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(200, 5000, 512, 0.001, 0.001)</td>\n",
       "      <td>0.643184</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>(200, 5000, 512, 0.001, 0.0001)</td>\n",
       "      <td>0.643163</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>(200, 5000, 512, 0.0001, 0.001)</td>\n",
       "      <td>0.376980</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>(200, 5000, 512, 0.0001, 0.0001)</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>(250, 4000, 256, 0.001, 0.001)</td>\n",
       "      <td>0.677694</td>\n",
       "      <td>0.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>(250, 4000, 256, 0.001, 0.0001)</td>\n",
       "      <td>0.676857</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>(250, 4000, 256, 0.0001, 0.001)</td>\n",
       "      <td>0.415510</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>(250, 4000, 256, 0.0001, 0.0001)</td>\n",
       "      <td>0.415245</td>\n",
       "      <td>0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>(250, 4000, 512, 0.001, 0.001)</td>\n",
       "      <td>0.637531</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>(250, 4000, 512, 0.001, 0.0001)</td>\n",
       "      <td>0.638959</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>(250, 4000, 512, 0.0001, 0.001)</td>\n",
       "      <td>0.373714</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>(250, 4000, 512, 0.0001, 0.0001)</td>\n",
       "      <td>0.373714</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>(250, 5000, 256, 0.001, 0.001)</td>\n",
       "      <td>0.711367</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>(250, 5000, 256, 0.001, 0.0001)</td>\n",
       "      <td>0.710776</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>(250, 5000, 256, 0.0001, 0.001)</td>\n",
       "      <td>0.426939</td>\n",
       "      <td>0.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>(250, 5000, 256, 0.0001, 0.0001)</td>\n",
       "      <td>0.426816</td>\n",
       "      <td>0.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>(250, 5000, 512, 0.001, 0.001)</td>\n",
       "      <td>0.648612</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>(250, 5000, 512, 0.001, 0.0001)</td>\n",
       "      <td>0.650571</td>\n",
       "      <td>0.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>(250, 5000, 512, 0.0001, 0.001)</td>\n",
       "      <td>0.378776</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>(250, 5000, 512, 0.0001, 0.0001)</td>\n",
       "      <td>0.378755</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                      combinations  train accuracy  val accuracy\n",
       "0            0    (200, 4000, 256, 0.001, 0.001)        0.664857         0.530\n",
       "1            1   (200, 4000, 256, 0.001, 0.0001)        0.665939         0.544\n",
       "2            2   (200, 4000, 256, 0.0001, 0.001)        0.412286         0.420\n",
       "3            3  (200, 4000, 256, 0.0001, 0.0001)        0.412306         0.420\n",
       "4            4    (200, 4000, 512, 0.001, 0.001)        0.632755         0.534\n",
       "5            5   (200, 4000, 512, 0.001, 0.0001)        0.633082         0.536\n",
       "6            6   (200, 4000, 512, 0.0001, 0.001)        0.372020         0.373\n",
       "7            7  (200, 4000, 512, 0.0001, 0.0001)        0.371959         0.373\n",
       "8            8    (200, 5000, 256, 0.001, 0.001)        0.692286         0.531\n",
       "9            9   (200, 5000, 256, 0.001, 0.0001)        0.694714         0.523\n",
       "10          10   (200, 5000, 256, 0.0001, 0.001)        0.425061         0.431\n",
       "11          11  (200, 5000, 256, 0.0001, 0.0001)        0.425163         0.431\n",
       "12          12    (200, 5000, 512, 0.001, 0.001)        0.643184         0.540\n",
       "13          13   (200, 5000, 512, 0.001, 0.0001)        0.643163         0.542\n",
       "14          14   (200, 5000, 512, 0.0001, 0.001)        0.376980         0.379\n",
       "15          15  (200, 5000, 512, 0.0001, 0.0001)        0.377000         0.379\n",
       "16          16    (250, 4000, 256, 0.001, 0.001)        0.677694         0.553\n",
       "17          17   (250, 4000, 256, 0.001, 0.0001)        0.676857         0.551\n",
       "18          18   (250, 4000, 256, 0.0001, 0.001)        0.415510         0.422\n",
       "19          19  (250, 4000, 256, 0.0001, 0.0001)        0.415245         0.421\n",
       "20          20    (250, 4000, 512, 0.001, 0.001)        0.637531         0.546\n",
       "21          21   (250, 4000, 512, 0.001, 0.0001)        0.638959         0.543\n",
       "22          22   (250, 4000, 512, 0.0001, 0.001)        0.373714         0.375\n",
       "23          23  (250, 4000, 512, 0.0001, 0.0001)        0.373714         0.375\n",
       "24          24    (250, 5000, 256, 0.001, 0.001)        0.711367         0.563\n",
       "25          25   (250, 5000, 256, 0.001, 0.0001)        0.710776         0.540\n",
       "26          26   (250, 5000, 256, 0.0001, 0.001)        0.426939         0.434\n",
       "27          27  (250, 5000, 256, 0.0001, 0.0001)        0.426816         0.434\n",
       "28          28    (250, 5000, 512, 0.001, 0.001)        0.648612         0.548\n",
       "29          29   (250, 5000, 512, 0.001, 0.0001)        0.650571         0.553\n",
       "30          30   (250, 5000, 512, 0.0001, 0.001)        0.378776         0.383\n",
       "31          31  (250, 5000, 512, 0.0001, 0.0001)        0.378755         0.383"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(df[\"combinations\"])\n",
    "df[\"hidden size\"], df[\"number of iterations\"], df[\"batch size\"], df[\"learning rate\"], df[\"regularization\"] = 0,0,0,0,0\n",
    "for n,tuple_ in enumerate(a):\n",
    "    df[\"hidden size\"].iloc[n] = eval(tuple_)[0]\n",
    "    df[\"number of iterations\"].iloc[n] = eval(tuple_)[1]\n",
    "    df[\"batch size\"].iloc[n] = eval(tuple_)[2]\n",
    "    df[\"learning rate\"].iloc[n] = eval(tuple_)[3]\n",
    "    df[\"regularization\"].iloc[n] = eval(tuple_)[4]\n",
    "df.drop([\"combinations\", \"Unnamed: 0\"], axis = 1, inplace  =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>val accuracy</th>\n",
       "      <th>hidden size</th>\n",
       "      <th>number of iterations</th>\n",
       "      <th>batch size</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>regularization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120816</td>\n",
       "      <td>0.134</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.120816</td>\n",
       "      <td>0.134</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.098</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.098</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.128694</td>\n",
       "      <td>0.140</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.128694</td>\n",
       "      <td>0.140</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.095735</td>\n",
       "      <td>0.100</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.095735</td>\n",
       "      <td>0.100</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.139</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.139</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.101571</td>\n",
       "      <td>0.083</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.101571</td>\n",
       "      <td>0.083</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.146776</td>\n",
       "      <td>0.132</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.146776</td>\n",
       "      <td>0.132</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.101408</td>\n",
       "      <td>0.085</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.101408</td>\n",
       "      <td>0.085</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train accuracy  val accuracy  hidden size  number of iterations  \\\n",
       "0         0.120816         0.134          200                     1   \n",
       "1         0.120816         0.134          200                     1   \n",
       "2         0.095551         0.098          200                     1   \n",
       "3         0.095551         0.098          200                     1   \n",
       "4         0.128694         0.140          200                     1   \n",
       "5         0.128694         0.140          200                     1   \n",
       "6         0.095735         0.100          200                     1   \n",
       "7         0.095735         0.100          200                     1   \n",
       "8         0.145510         0.139          250                     1   \n",
       "9         0.145510         0.139          250                     1   \n",
       "10        0.101571         0.083          250                     1   \n",
       "11        0.101571         0.083          250                     1   \n",
       "12        0.146776         0.132          250                     1   \n",
       "13        0.146776         0.132          250                     1   \n",
       "14        0.101408         0.085          250                     1   \n",
       "15        0.101408         0.085          250                     1   \n",
       "\n",
       "    batch size  learning rate  regularization  \n",
       "0          256         0.0010          0.0010  \n",
       "1          256         0.0010          0.0001  \n",
       "2          256         0.0001          0.0010  \n",
       "3          256         0.0001          0.0001  \n",
       "4          512         0.0010          0.0010  \n",
       "5          512         0.0010          0.0001  \n",
       "6          512         0.0001          0.0010  \n",
       "7          512         0.0001          0.0001  \n",
       "8          256         0.0010          0.0010  \n",
       "9          256         0.0010          0.0001  \n",
       "10         256         0.0001          0.0010  \n",
       "11         256         0.0001          0.0001  \n",
       "12         512         0.0010          0.0010  \n",
       "13         512         0.0010          0.0001  \n",
       "14         512         0.0001          0.0010  \n",
       "15         512         0.0001          0.0001  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"corrected results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import two_layernet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from two_layernet import TwoLayerNet\n",
    "from gradient_check import eval_numerical_gradient\n",
    "from data_utils import get_CIFAR10_data\n",
    "from vis_utils import visualize_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3072)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current combination : (200, 100, 256, 0.001, 0.001)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:03<00:03,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current combination : (200, 100, 512, 0.001, 0.001)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 100, 512, 0.001, 0.001) [0.302, 0.316]\n",
      "{'loss_history': [2.3025927086467615, 2.3025010675306716, 2.302390526752789, 2.302257356654443, 2.302185241465644, 2.3020421573640495, 2.301945517205655, 2.3016463916202734, 2.301726818259029, 2.3012325078780664, 2.3009415172430483, 2.30058403724026, 2.300229357525976, 2.2997284796477158, 2.2985535533028387, 2.297666495303832, 2.2956656567840388, 2.2950007764478717, 2.2923153582875626, 2.290239310582664, 2.286698472530722, 2.2836691236892848, 2.282971245592869, 2.2799031753749723, 2.274310389290027, 2.2686790127827745, 2.2625605132025597, 2.2549498724138637, 2.241281039729629, 2.248566628850613, 2.2414541277630455, 2.222610854149397, 2.2098296513056415, 2.1873182965071694, 2.192660443309267, 2.202039961099017, 2.192778906317946, 2.151569537891069, 2.159022846238599, 2.1260425977876958, 2.158849230990841, 2.143960858040442, 2.136058732259156, 2.108305467191329, 2.075832578599958, 2.100740793597214, 2.100782495752944, 2.0492113086310435, 2.091224419742057, 2.0276940743100367, 2.1077730652214406, 2.0859205103273406, 2.1042692887815595, 2.0202154873537754, 2.0525481656801086, 2.0335026447405697, 2.0591553760649863, 2.0524997210899807, 2.019421268756732, 2.0354545955238272, 2.0072899080229267, 2.05094906510559, 2.040855460985805, 2.0519894948448414, 2.0197342179783915, 1.9935992877324755, 1.9889915563559055, 1.9393156735552606, 2.0530887701570806, 1.9962553177578535, 1.95880794754782, 1.9840534789165507, 2.0195784194102893, 1.9726584056882355, 1.9734434080721606, 1.954734004879835, 2.005528344567551, 1.9757946531814443, 2.009712172538313, 1.9787640583517274, 1.9543918608617779, 1.9002076470963158, 1.8845322601586836, 1.9459585467509783, 1.937662703159534, 1.9217171764509722, 1.9380326280794407, 1.949270531540703, 1.981967667269818, 1.8976439965724503, 1.917986278609598, 1.9265548530531489, 1.8666711928670088, 1.9227136940895295, 1.906425004401421, 1.910510614064336, 1.8919098527525755, 1.9214511507449676, 1.9128965844747539, 1.9133442671119731], 'train_acc_history': [0.193359375, 0.318359375], 'val_acc_history': [0.161, 0.306]}\n",
      "-----------\n",
      "hidden size:  200 , num_iters:  100 , batch size:  512 , learning_rate:  0.001 , regula:  0.001\n",
      "Validation accuracy:  0.316\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "\n",
    "param_grid = {\n",
    "\"hidden_size\" : [200], \"niter\" : [100],\"batch\":[256, 512], \n",
    "\"lerate\": [1e-3], \"reg\" : [1e-3]\n",
    "}\n",
    "results_val = []\n",
    "results_train = []\n",
    "combinations = list(itertools.product(*param_grid.values()))\n",
    "for comb in tqdm(combinations):\n",
    "    \n",
    "    \n",
    "    print(\"current combination :\", comb)\n",
    "    print(\"\\n\")\n",
    "    # Train the network\n",
    "    np.random.seed(0)\n",
    "    net = TwoLayerNet(input_size, comb[0], num_classes)\n",
    "    stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=comb[1], batch_size=comb[2],\n",
    "            learning_rate=comb[3], learning_rate_decay=0.95,\n",
    "            reg=comb[4], verbose=False)\n",
    "    val_acc = (net.predict(X_val) == y_val).mean()\n",
    "    if val_acc == 0.162:\n",
    "        pass\n",
    "    train_acc = (net.predict(X_train) == y_train).mean()\n",
    "    results_val.append(val_acc)\n",
    "    results_train.append(train_acc)\n",
    "\n",
    "best_comb = combinations[results_val.index(max(results_val))]\n",
    "print(best_comb, results_val)\n",
    "zipped = list(zip(combinations,results_train, results_val))\n",
    "pd.DataFrame(zipped).rename(columns = {0:\"combinations\",1:\"train accuracy\",2:\"val accuracy\"}).to_csv(\"results\")\n",
    "#best_comb = (200, 5000, 512, 0.001, 0.001)\n",
    "#print(zipped, best_comb, results_val)\n",
    "np.random.seed(0)\n",
    "best_net = TwoLayerNet(input_size, best_comb[0], num_classes)\n",
    "stats = best_net.train(X_train, y_train, X_val, y_val,\n",
    "        num_iters=best_comb[1], batch_size=best_comb[2],\n",
    "        learning_rate=best_comb[3], learning_rate_decay=0.95,\n",
    "        reg=best_comb[4], verbose=False)\n",
    "\n",
    "\n",
    "print(stats) \n",
    "# Predict on the validation set\n",
    "print('-----------')\n",
    "print('hidden size: ',best_comb[0], ', num_iters: ',best_comb[1], ', batch size: ',best_comb[2], ', learning_rate: ', best_comb[3], ', regula: ',best_comb[4] )\n",
    "val_acc = (best_net.predict(X_val) == y_val).mean()\n",
    "print('Validation accuracy: ', val_acc)\n",
    "print('------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
